{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = 'data/train.csv' \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excluding at the moment all the columns that contains NaN (Data set to zero or -999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 19)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def exclude_NaN(tX):\n",
    "    sort_no_NaN= [1,2,3,7,8,9,10,11,13,14,15,16,17,18,19,20,21,28,29]\n",
    "    tX_reduced = tX[:,sort_no_NaN]\n",
    "    return tX_reduced\n",
    "tX = exclude_NaN(tX)\n",
    "tX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization of the data, to get 0 mean and unit variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.69328881937\n"
     ]
    }
   ],
   "source": [
    "def normalize(tX):\n",
    "    print(np.mean(tX))\n",
    "normalize(tX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing something with gradient descent first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first try out with some simple least squares, which should give a bad solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gradient_descent as gd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N0=500\n",
    "losses0,w = gd.gradient_descent_MAE(y,tX2,[0.5]*19,N,0.00005)\n",
    "N=2000 \n",
    "losses,w = gd.gradient_descent_MAE(y,tX2,w[N0-1],N,0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses : 11.538227599\n"
     ]
    }
   ],
   "source": [
    "print('Losses :',losses[N-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to compute the error made by our prediction with RMSE measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import costs as co\n",
    "def RMSE(y,tX,weight):\n",
    "    return np.sqrt(2*co.compute_loss(y,tX,weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = w[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.7403783201110983"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE(y,tX2,weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will do prediction on our test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = 'data/test.csv'  # TODO: download train data and supply path here \n",
    "y_test, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "tX_test_sorted = exclude_NaN(tX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'data/output.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, tX_test_sorted)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying out Ridge regression now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(x, y, ratio, seed=1):\n",
    "    \"\"\" Split the dataset based on the split ratio.\n",
    "        The order is : x_train, x_test,y_train,y_test\n",
    "    \"\"\"\n",
    "    # set seed\n",
    "    np.random.seed(seed)\n",
    "    assert len(x)==len(y)\n",
    "    p = np.random.permutation(len(x))\n",
    "    x_train,x_test = np.split(x[p],[int(ratio*len(x))])\n",
    "    y_train,y_test = np.split(y[p],[int(ratio*len(y))])\n",
    "    return x_train,x_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lambda =0.0001, proportion=0.5, degree=2, Training RMSE=0.815, Testing RMSE=1.019\n",
      "lambda =0.00020691380811147902, proportion=0.5, degree=2, Training RMSE=0.815, Testing RMSE=1.019\n",
      "lambda =0.00042813323987193956, proportion=0.5, degree=2, Training RMSE=0.815, Testing RMSE=1.019\n",
      "lambda =0.0008858667904100823, proportion=0.5, degree=2, Training RMSE=0.815, Testing RMSE=1.019\n",
      "lambda =0.0018329807108324356, proportion=0.5, degree=2, Training RMSE=0.815, Testing RMSE=1.019\n",
      "lambda =0.00379269019073225, proportion=0.5, degree=2, Training RMSE=0.815, Testing RMSE=1.019\n",
      "lambda =0.007847599703514606, proportion=0.5, degree=2, Training RMSE=0.815, Testing RMSE=1.019\n",
      "lambda =0.01623776739188721, proportion=0.5, degree=2, Training RMSE=0.815, Testing RMSE=1.019\n",
      "lambda =0.03359818286283781, proportion=0.5, degree=2, Training RMSE=0.815, Testing RMSE=1.019\n",
      "lambda =0.06951927961775606, proportion=0.5, degree=2, Training RMSE=0.815, Testing RMSE=1.019\n",
      "lambda =0.14384498882876628, proportion=0.5, degree=2, Training RMSE=0.815, Testing RMSE=1.019\n",
      "lambda =0.29763514416313164, proportion=0.5, degree=2, Training RMSE=0.815, Testing RMSE=1.019\n",
      "lambda =0.615848211066026, proportion=0.5, degree=2, Training RMSE=0.815, Testing RMSE=1.019\n",
      "lambda =1.2742749857031321, proportion=0.5, degree=2, Training RMSE=0.815, Testing RMSE=1.019\n",
      "lambda =2.6366508987303554, proportion=0.5, degree=2, Training RMSE=0.815, Testing RMSE=1.019\n",
      "lambda =5.455594781168514, proportion=0.5, degree=2, Training RMSE=0.815, Testing RMSE=1.019\n",
      "lambda =11.288378916846883, proportion=0.5, degree=2, Training RMSE=0.815, Testing RMSE=1.019\n",
      "lambda =23.357214690901213, proportion=0.5, degree=2, Training RMSE=0.815, Testing RMSE=1.019\n",
      "lambda =48.32930238571752, proportion=0.5, degree=2, Training RMSE=0.815, Testing RMSE=1.019\n",
      "lambda =100.0, proportion=0.5, degree=2, Training RMSE=0.815, Testing RMSE=1.020\n"
     ]
    }
   ],
   "source": [
    "import ridge_regression as rr\n",
    "import build_polynomial as bp\n",
    "def ridge_regression_demo(x, y, degree, ratio, seed):\n",
    "    \"\"\"ridge regression demo.\"\"\"\n",
    "    # define parameter\n",
    "    lambdas = np.logspace(-4, 2, 20)   \n",
    "    weights_arr = np.zeros((len(lambdas),(degree+1)*tX2.shape[1]))\n",
    "    rmse_tr = np.zeros(len(lambdas))\n",
    "    rmse_te = np.zeros(len(lambdas))\n",
    "    # ***************************************************\n",
    "    # split the data, and return train and test data:\n",
    "    # ***************************************************\n",
    "    x_train,x_test,y_train,y_test = split_data(x,y,ratio,seed)\n",
    "    \n",
    "    # ***************************************************\n",
    "    # form train and test data with polynomial basis function:\n",
    "    # ***************************************************\n",
    "    X_train = new_build_poly(x_train, degree)\n",
    "    X_test = new_build_poly(x_test, degree)    \n",
    "    \n",
    "    # ***************************************************\n",
    "    # ridge regression with different lambda: TODO\n",
    "    # ***************************************************\n",
    "    for i,lambd in enumerate(lambdas):\n",
    "        #print(weights_arr[i,:].shape, ' ',X_train.shape)\n",
    "        weights_arr[i,:] = rr.ridge_regression(y_train,X_train,lambd)\n",
    "        rmse_tr[i] = np.sqrt(2*co.compute_loss(y_train,X_train,weights_arr[i,:]))\n",
    "        rmse_te[i] = np.sqrt(2*co.compute_loss(y_test,X_test,weights_arr[i,:]))\n",
    "                \n",
    "        print(\"lambda ={l}, proportion={p}, degree={d}, Training RMSE={tr:.3f}, Testing RMSE={te:.3f}\".format(\n",
    "                l=lambd,p=ratio, d=degree, tr=rmse_tr[i], te=rmse_te[i]))\n",
    "    return lambdas, rmse_tr,rmse_te\n",
    "\n",
    "seed = 6\n",
    "degree = 2\n",
    "split_ratio = 0.5\n",
    "lambd, rmse_tr,rmse_te = ridge_regression_demo(tX2, y, degree, split_ratio, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test for a build_poly function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def new_build_poly(x, degree):\n",
    "    \"\"\"polynomial basis function.\"\"\"\n",
    "    # Creates the matrix with the degrees we want to apply to our data x\n",
    "    # replecating the vector with [1 2 3 4 ... degree] to a matrix\n",
    "    #degree_mat = np.tile(list(range(0,degree+1)), (len(x), 1))\n",
    "    #return np.transpose(np.power(x,np.transpose(degree_mat)))\n",
    "    \n",
    "    #Seulement 1 1, parce qu'il n'y a pas besoin de 30\n",
    "    \n",
    "    X=np.zeros((x.shape[0],(degree+1)*x.shape[1]))\n",
    "    for i in range(degree+1):\n",
    "        for j in range(x.shape[1]):\n",
    "            #print(i*x.shape[1]+j)\n",
    "            X[:,i*x.shape[1]+j]=x[:,j]**i\n",
    "    return X"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
