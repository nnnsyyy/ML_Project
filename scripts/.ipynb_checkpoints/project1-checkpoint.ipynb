{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = 'data/train.csv' \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excluding at the moment all the columns that contains NaN (Data set to zero or -999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 19)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def exclude_NaN(tX):\n",
    "    sort_no_NaN= [1,2,3,7,8,9,10,11,13,14,15,16,17,18,19,20,21,28,29]\n",
    "    tX_reduced = tX[:,sort_no_NaN]\n",
    "    return tX_reduced\n",
    "tX2 = exclude_NaN(tX)\n",
    "tX2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing something with gradient descent first"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first try out with some simple least squares, which should give a bad solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import gradient_descent as gd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N0=500\n",
    "losses0,w = gd.gradient_descent_MAE(y,tX2,[0.5]*19,N,0.00005)\n",
    "N=2000 \n",
    "losses,w = gd.gradient_descent_MAE(y,tX2,w[N0-1],N,0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses : 11.538227599\n"
     ]
    }
   ],
   "source": [
    "print('Losses :',losses[N-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to compute the error made by our prediction with RMSE measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import costs as co\n",
    "def RMSE(y,tX,weight):\n",
    "    return np.sqrt(2*co.compute_loss(y,tX,weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weights = w[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.7403783201110983"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RMSE(y,tX2,weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will do prediction on our test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate predictions and save ouput in csv format for submission:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DATA_TEST_PATH = 'data/test.csv'  # TODO: download train data and supply path here \n",
    "y_test, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n",
    "tX_test_sorted = exclude_NaN(tX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "OUTPUT_PATH = 'data/output.csv' # TODO: fill in desired name of output file for submission\n",
    "y_pred = predict_labels(weights, tX_test_sorted)\n",
    "create_csv_submission(ids_test, y_pred, OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying out Ridge regression now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(x, y, ratio, seed=1):\n",
    "    \"\"\" Split the dataset based on the split ratio.\n",
    "        The order is : x_train, x_test,y_train,y_test\n",
    "    \"\"\"\n",
    "    # set seed\n",
    "    np.random.seed(seed)\n",
    "    assert len(x)==len(y)\n",
    "    p = np.random.permutation(len(x))\n",
    "    x_train,x_test = np.split(x[p],[int(ratio*len(x))])\n",
    "    y_train,y_test = np.split(y[p],[int(ratio*len(y))])\n",
    "    return x_train,x_test,y_train,y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (125000,19) (2,125000) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-24b13fa7e5e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mdegree\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[0msplit_ratio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.5\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m \u001b[0mlambd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrmse_tr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mrmse_te\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mridge_regression_demo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtX2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit_ratio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-55-24b13fa7e5e9>\u001b[0m in \u001b[0;36mridge_regression_demo\u001b[1;34m(x, y, degree, ratio, seed)\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m# form train and test data with polynomial basis function:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m# ***************************************************\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_poly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m     \u001b[0mX_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild_poly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/home/thomas/Documents/EPFL/5eme - 2e Master/Machine Learning/ML_course/projects/project1/scripts/build_polynomial.py\u001b[0m in \u001b[0;36mbuild_poly\u001b[1;34m(x, degree)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;31m# replecating the vector with [1 2 3 4 ... degree] to a matrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m#degree_mat = np.tile(list(range(0,degree+1)), (len(x), 1))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[1;31m#return np.transpose(np.power(x,np.transpose(degree_mat)))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdegree\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdegree\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (125000,19) (2,125000) "
     ]
    }
   ],
   "source": [
    "import ridge_regression as rr\n",
    "import build_polynomial as bp\n",
    "def ridge_regression_demo(x, y, degree, ratio, seed):\n",
    "    \"\"\"ridge regression demo.\"\"\"\n",
    "    # define parameter\n",
    "    lambdas = np.logspace(-3, 1, 10)   \n",
    "    weights_arr = np.zeros((len(lambdas),(degree*tX2.shape[1]+1)))\n",
    "    rmse_tr = np.zeros(len(lambdas))\n",
    "    rmse_te = np.zeros(len(lambdas))\n",
    "    # ***************************************************\n",
    "    # split the data, and return train and test data:\n",
    "    # ***************************************************\n",
    "    x_train,x_test,y_train,y_test = split_data(x,y,ratio,seed)\n",
    "    \n",
    "    # ***************************************************\n",
    "    # form train and test data with polynomial basis function:\n",
    "    # ***************************************************\n",
    "    X_train = bp.build_poly(x_train, degree)\n",
    "    X_test = bp.build_poly(x_test, degree)    \n",
    "    \n",
    "    # ***************************************************\n",
    "    # ridge regression with different lambda: TODO\n",
    "    # ***************************************************\n",
    "    for i,lambd in enumerate(lambdas):\n",
    "        weights_arr[i,:] = rr.ridge_regression(y_train,X_train,lambd)\n",
    "        rmse_tr[i] = np.sqrt(2*co.compute_loss(y_train,X_train,weights[i,:]))\n",
    "        rmse_te[i] = np.sqrt(2*co.compute_loss(y_test,X_test,weights[i,:]))\n",
    "    return lambdas, rmse_tr,rmse_te\n",
    "\n",
    "seed = 6\n",
    "degree = 1\n",
    "split_ratio = 0.5\n",
    "lambd, rmse_tr,rmse_te = ridge_regression_demo(tX2, y, degree, split_ratio, seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of build_polynomial failed: Traceback (most recent call last):\n",
      "  File \"/home/thomas/anaconda3/lib/python3.5/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/thomas/Documents/EPFL/5eme - 2e Master/Machine Learning/ML_course/projects/project1/scripts/build_polynomial.py\", line 15\n",
      "    for j in range(x.shape[1]):\n",
      "                              ^\n",
      "TabError: inconsistent use of tabs and spaces in indentation\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ -7.97603393e-03,  -4.49440103e-03,   8.63920674e-05,\n",
       "         2.04809819e-01,  -1.52310040e-03,  -4.12453074e-02,\n",
       "        -2.89375440e-01,   1.14397992e-01,   4.63940439e-02,\n",
       "        -9.60873172e-04,  -9.33938263e-04,   5.45720885e-02,\n",
       "         2.99878767e-04,   8.15917639e-04,   2.54280654e-03,\n",
       "         4.94176691e-04,  -9.38387990e-04,   3.38628633e-04,\n",
       "         4.03634574e-02])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rr.ridge_regression(y,tX2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def new_build_poly(x, degree):\n",
    "    \"\"\"polynomial basis function.\"\"\"\n",
    "    # Creates the matrix with the degrees we want to apply to our data x\n",
    "    # replecating the vector with [1 2 3 4 ... degree] to a matrix\n",
    "    #degree_mat = np.tile(list(range(0,degree+1)), (len(x), 1))\n",
    "    #return np.transpose(np.power(x,np.transpose(degree_mat)))\n",
    "    X=np.zeros((x.shape[0],(degree+1)*x.shape[1]))\n",
    "    for i in range(degree+1):\n",
    "        for j in range(x.shape[1]):\n",
    "            print(i*x.shape[1]+j)\n",
    "            X[:,i*x.shape[1]+j]=x[:,j]**i\n",
    "    return X"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
