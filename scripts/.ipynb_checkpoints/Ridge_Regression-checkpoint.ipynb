{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementatation of ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the training data into feature matrix, class labels, and event ids:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import *\n",
    "DATA_TRAIN_PATH = 'data/train.csv' \n",
    "y, tX, ids = load_csv_data(DATA_TRAIN_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excluding at the moment all the columns that contains NaN (Data set to zero or -999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def exclude_NaN(tX):\n",
    "    sort_no_NaN= [1,2,3,7,8,9,10,11,13,14,15,16,17,18,19,20,21,28,29]\n",
    "    tX_reduced = tX[:,sort_no_NaN]\n",
    "    return tX_reduced\n",
    "tX = exclude_NaN(tX)\n",
    "tX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sanitize_NaN(tX):\n",
    "    x = tX.copy()\n",
    "    negative_NaN_table = np.array([0,4,5,6,12,23,24,25,26,27,28])\n",
    "    NEGATIVE_NAN = -999.0\n",
    "    zero_NaN_table = [29]\n",
    "    ZERO_NAN = 0\n",
    "    for row in negative_NaN_table:\n",
    "        x_without_nan = x[:,row][np.where(x[:,row] != NEGATIVE_NAN)]\n",
    "        x[:,row][np.where(x[:,row] == NEGATIVE_NAN)] = np.median(x_without_nan)\n",
    "    for row in zero_NaN_table:\n",
    "         x_without_nan = x[:,row][np.where(x[:,row] != ZERO_NAN)]\n",
    "        x[:,row][np.where(x[:,row] == NEGATIVE_NAN)] = np.median(x_without_nan)\n",
    "    return x\n",
    "\n",
    "tX2 = sanitize_NaN(tX)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 160.937 -999.     143.905  175.864   89.744  148.754  154.916  105.594\n",
      "  128.053]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "121.85852835958957"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tX[1:10,0])\n",
    "np.mean(tX[:,0][np.where(tX[:,0]!=-999.0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "120.41743369599999"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(tX2[:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization of the data, to get 0 mean and unit variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def normalize(tX):\n",
    "    return (tX-np.mean(tX,axis=0))/np.std(tX,axis=0)\n",
    "\n",
    "tX = normalize(tX)\n",
    "\n",
    "#We verify whether our data have really mean 0 and variance 1\n",
    "print(np.mean(tX,axis=0))\n",
    "print(np.std(tX,axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let us turn to the proper machine learning side of the problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function that builds a polynomial basis from each of the data entry (i.e. goes from $\\mathbb{R}^N$ to $\\mathbb{R}^{N\\cdot D + 1}$ for each data point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def new_build_poly(x, degree):\n",
    "    \"\"\"polynomial basis function.\"\"\"\n",
    "    # Creates the matrix with the degrees we want to apply to our data x\n",
    "    # replecating the vector with [1 2 3 4 ... degree] to a matrix\n",
    "    #degree_mat = np.tile(list(range(0,degree+1)), (len(x), 1))\n",
    "    #return np.transpose(np.power(x,np.transpose(degree_mat)))\n",
    "    \n",
    "    # Only 1 time 1, because we don't need it to be repeated. That's why for M features and a polynomial of degree D,\n",
    "    # we will get M*D+1 entries.\n",
    "    X=np.zeros((x.shape[0],(degree)*x.shape[1]+1))\n",
    "    for i in range(1,degree+1):\n",
    "        for j in range(x.shape[1]):\n",
    "            #print((i-1)*(x.shape[1])+j+1)\n",
    "            X[:,(i-1)*x.shape[1]+j+1]=x[:,j]**i\n",
    "    X[:,0]=1\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing 4-fold cross-validation in the following two methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_k_indices(y, k_fold, seed):\n",
    "    \"\"\"build k indices for k-fold.\"\"\"\n",
    "    num_row = y.shape[0]\n",
    "    interval = int(num_row / k_fold)\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    k_indices = [indices[k * interval: (k + 1) * interval]\n",
    "                 for k in range(k_fold)]\n",
    "    return np.array(k_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from costs import compute_mse\n",
    "from ridge_regression import ridge_regression\n",
    "\n",
    "def cross_validation(y, x, k_indices, k, lambda_, degree):\n",
    "    \"\"\"return the loss of ridge regression.\"\"\"\n",
    "    # ***************************************************\n",
    "    # get k'th subgroup in test, others in train: \n",
    "    # ***************************************************\n",
    "    x_train = np.array(x[k_indices[k-1]])\n",
    "    y_train = np.array(y[k_indices[k-1]])\n",
    "    x_test = np.empty((0,x.shape[1]))\n",
    "    y_test =  np.empty((0,1))\n",
    "    for k_iter,validation_points in enumerate(k_indices):\n",
    "        if(k_iter!=k-1):\n",
    "            x_test=np.append(x_test,x[validation_points],axis=0)\n",
    "            y_test=np.append(y_test,y[validation_points])\n",
    "    #print(x_test.shape)\n",
    "    #print(y_test.shape)\n",
    "    # ***************************************************\n",
    "    # form data with polynomial degree:\n",
    "    # ***************************************************\n",
    "    x_train_poly = new_build_poly(x_train,degree)\n",
    "    x_test_poly = new_build_poly(x_test,degree)\n",
    "    # ***************************************************\n",
    "    # ridge regression: \n",
    "    # ***************************************************\n",
    "    w_rr = ridge_regression(y_train,x_train_poly,lambda_)\n",
    "    # ***************************************************\n",
    "    # calculate the loss for train and test data:\n",
    "    # ***************************************************\n",
    "    #print(x_train_poly.dot(w_rr).shape)\n",
    "    #print(y_train.shape)\n",
    "    loss_tr = np.sqrt(2*compute_mse(y_train,x_train_poly,w_rr))\n",
    "    loss_te = np.sqrt(2*compute_mse(y_test,x_test_poly,w_rr))\n",
    "    return loss_tr, loss_te"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementation of the ridge regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ridge_regression(y, tx, lamb):\n",
    "    \"\"\"implement ridge regression.\"\"\"\n",
    "    return np.linalg.solve(np.dot(tx.T,tx)+lamb*np.identity(tx.shape[1]),np.dot(tx.T,y))#/(2*len(tx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'build_poly' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-35a3c9d774fb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mweights_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[0mweights_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrun_ridge_regression\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-35a3c9d774fb>\u001b[0m in \u001b[0;36mrun_ridge_regression\u001b[1;34m(y, tX)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m# train on the whole data and use polynomial basis functions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;31m# ***************************************************\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mtX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuild_poly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdegree\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m     \u001b[1;31m# ***************************************************\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'build_poly' is not defined"
     ]
    }
   ],
   "source": [
    "def run_ridge_regression(y, tX):\n",
    "    \"\"\"ridge regression running script.\"\"\"\n",
    "    \n",
    "    # define parameters for our run   \n",
    "    seed = 6\n",
    "    degree = 2\n",
    "    split_ratio = 0.5\n",
    "    lambdas = np.logspace(-4, 2, 20)   \n",
    "    weights_arr = np.zeros((len(lambdas),(degree)*tX.shape[1]+1))\n",
    "    errors = []\n",
    "    # ***************************************************\n",
    "    # train on the whole data and use polynomial basis functions\n",
    "    # ***************************************************\n",
    "    tX_train = build_poly(tX, degree)\n",
    "    \n",
    "    # ***************************************************\n",
    "    # ridge regression with different lambdas: \n",
    "    # ***************************************************\n",
    "    for i,lambd in enumerate(lambdas):\n",
    "        #print(weights_arr[i,:].shape, ' ',X_train.shape)\n",
    "        weights_arr[i,:] = ridge_regression(y,tX_train,lambd)\n",
    "        \n",
    "        #rmse_tr[i] = np.sqrt(2*co.compute_loss(y_train,X_train,weights_arr[i,:]))\n",
    "        #rmse_te[i] = np.sqrt(2*co.compute_loss(y_test,X_test,weights_arr[i,:]))\n",
    "                \n",
    "        #print(\"lambda ={l}, proportion={p}, degree={d}, Training RMSE={tr:.3f}, Testing RMSE={te:.3f}\".format(\n",
    "        #        l=lambd,p=ratio, d=degree, tr=rmse_tr[i], te=rmse_te[i]))\n",
    "    return weights_arr, errors\n",
    "\n",
    "weights_arr, errors = run_ridge_regression(y, tX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Testing for a polynomial of degree  1\n",
      "lambda=0.0001, 0.000464, 0.002154, 0.01, 0.046416, 0.215443, 1.0, 4.641589, 21.544347, 100.0, \n",
      " Testing for a polynomial of degree  2\n",
      "lambda=0.0001, 0.000464, 0.002154, 0.01, 0.046416, 0.215443, 1.0, 4.641589, 21.544347, 100.0, \n",
      "Best error : [ 1.04778258  1.12980849]\n",
      "Best lambda : [ 1.          0.04641589]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZAAAAEdCAYAAAAikTHKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xt8VPWd//HXBxJowzXcEUhC0apAAd1d72jEWiqrrXVb\nq1Uu9mKl1e1Pu2tbXcvaXd1169It1qIIArHFS219KK611GICKtLW6moFrBYDCAKiYIYgCMnn98c5\nCUOYCZO5ZG7v5+Mxj8y5zDmfz5zJfOZ8vzPna+6OiIhIR3XJdgAiIpKfVEBERCQpKiAiIpIUFRAR\nEUmKCoiIiCRFBURERJKiAiLSiczsTTObFN7/npnNS2TdJPZzhpmtTTZOkUSUZDsAkWLl7v+Rrm2Z\nWTNwtLuvD7f9DHB8urYvEovOQKSgmFnXbMeQJfpFsHQ6FRDJC2Y23Mx+aWbbzewdM5sTzp9uZs+Y\n2Wwz2wHMssC/mFm9mW01s0Vm1jtcv7uZ3WdmO8xsp5mtNrOB4bIZZvZXM2sI/14aI46hZrbHzPpG\nzTshjKmrmX3MzH4Xbn+7mf2sZd8xtjXLzO6Lmp4axvyOmd3QZt2/M7Pnwpg3m9kdZlYSLqsDDHg5\njP0LZnaWmW2KevxxZvZ0+PhXzOyCqGULzewnZvZ4+PhVZjYyqQMlRUUFRHKemXUBHgfeBCqAYcAD\nUaucDLwBDAJuAa4ApgFnAR8DegF3hOtOB3qH2+gHXAV8YGZlwI+Bye7eGzgNeKltLO7+NvAc8A9R\nsy8FfuHuTQRv5LcCQwiakIYD/9pOeh7mOBr4KXAZcBTQP4yxRRPw/8KYTwUmAd8IYzorXOcT7t7b\n3X/RZtslwFLgSWAg8I/Az83smKjtfxGYBfQF/krwPIq0SwVE8sFJwFDgenff6+4fuvtzUcs3u/tP\n3b3Z3fcBXwJmu/sGd98DfA+4JCxE+wnenD/ugRfdfXe4nSbgE2b2EXff5u7xOqHvD/fR4hJgCYC7\n/9Xdf+fuB9z9XeBHBIXsSP4BWOruz7r7fuAmopql3P1P7v77MOaNwLwY27U42z4V6OHut4VxPU1Q\nkKPPsB5x9xfcvRn4OTAhgZilyKmASD4YAWwI39xi2dRm+ihgQ9T0BqAUGAzcB/wGeMDM3jKz/zSz\nrmGh+SIwE3jbzJaa2bFx9vdL4BQzG2xmZwFNYac1ZjbIzO4Pt70L+BkwIIEcj4rOI4zn3ZZpMzsm\njOntcLu3JLhdCIpv2+doA4ee4WyNur8H6JngtqWIqYBIPtgEVIRnELG07UDeAlRGTVcSnHlsCz+B\n/5u7jyFoprqAoLkLd/+tu3+KoPnpNeCemDtz3wUsIzjzuJRDm9NuBZqBMe7eF7ic+GcG0d4mKJQA\nhE1q/aOWzwXWAqPC7d6Y4HYheD5GtJlXAWxO8PEiMamASD74PcEb7H+aWVnYEX5aO+vfD1xrZlVm\n1pPg0/oD7t5sZtVmNjYsRrsJCktzeObwmfCNe3+4rOkI+5hG0PS0JGp+r/CxETMbBvxzgjk+DJxv\nZqeZWSnwAw4tEL2ABnffY2bHEZwpRdtK0N8Ty2pgj5ldb2YlZlYNnB/mIJI0FRDJeWHT1QXAMcBG\ngjOSi9t5yL0ETVUrCDqE9xB0HENwdvEw8D7wKvB0uG4X4DqCT+U7gDM5/E062mNhPG+7+ytR828G\n/gbYRdBx/cu26cTJcQ3wTYI39S0EzVdvRa3yT8BlZtYA3M2hZz0QdNTXmNl7Zvb5NtveT/D8TQlz\n+wkw1d1fby8mkSOxTA4oZWYLCD7pbHP3cTGWHwssBE4EbnD32W2WdwH+CLzl7p/JWKAiItJhmT4D\nWQhMbmf5u8A1wA/jLP8WsCbdQYmISOoyWkDCb6bsbGf5Dnd/ATjQdpmZDSc45Z6fuQhFRCRZudwH\n8iOCDki1z4qI5KCcvJiimf09Qb/JS+E3Rtr9uqKZqciIiHSQuyf6VfCYcvUM5HTgM2a2nuBbKWeb\nWU17D3D3pG+zZs1Keb14y9rOb2861v1EY8tGfonMK+T84uXa3jq5nF9Hj11n5peN/7105Jcz7y3X\nXIP/8If4aacxq7QUt5TqRqvOKCBGYj94al3H3W9w9wp3/xjBj7WWu/u0TAVYXV2d8nrxlrWd3950\nrPv19fUJxdaeTOWXyLxCzi9ertHz8ym/jh476Lz8svG/B6nnl7X3Fneqhw+Hf/1XGDeO6p/9DF5/\nHW66iepf/ALGHfal2OSk+umhvRvBD6y2APsIvr9/BfB14Mpw+WCC7/TvAt4L1+nZZhtnAY8dYT9e\nqKZPn57tEDJK+eU35ZdDDhxwX7nS/brr3EeODG7f/rb7M88Ey6I1NHj4vpnSe3xG+0Dc/UtHWL6N\nwy+x0HadOqAunXHlkxkzZmQ7hIxSfvlN+WXZhx/C8uXwyCPw6KMweDB87nPB9LhxEK+pqlevtOw+\noz8k7Cxm5oWQh4jIEe3eDb/+dVAkfv1rGD0aLroILrwQRo1KeDNmhhdoJ3paVFVVYWa65fDtqKOO\nyvbLJKNqa2uzHUJGKb9OsmMHLFwIn/kMDBsGCxbAWWfB2rXw7LPw7W93qHikS05+jTddNmzYgM5M\ncpul6dsgIgVn06bgLOORR+BPf4Jzz4VLLoGaGujb98iP7wQF3YQVnqJlISJJlI6RSJS1aw8WjTff\nhAsuCPo0zj0XPvrRtO4qHU1YKiCSVTpGUtTc4Q9/OFg0GhuDvozPfQ7OPBNKMtdIpD4QkRyXM23o\nGaL8knDgQPDNqWuugYoKmD49+LbUfffBxo1wxx0waVJGi0e65H6EIiL5LBKBF16ArVvhySfh8cdh\n5MjgLGPZMjj++GxHmDQ1YeWxmTNnMnz4cG688cZsh5K0Qj9GUsCam+G994JvSL3zzqG3lnlvvw2r\nVsHevdCjB8yaFXSEj2j352+dQn0goXwsICNHjmTBggVMmjQp26FkVS4fIykyH3548I2/vaLQctu5\nM/hB3sCBMGBA8Lft7Z134Prrg2ar0lJYsQJOOSXbmQLpKSCF04QViaTt15W5oKmpia5du2Y7DCB2\nLB2NL5fy6Uy1tbUJXw+pXZEI/PnPMHZs7rzOIxFqa2qonjYtp2JqfZ66dGm/ALSd19gI/fsffPMf\nMIDaDz+kesKEYHtR8xk4MFi3tPTI8SxeDGvWBD/4GzOmc56HTlI4BeSMM6CuLuEXcjr+H5PdxrRp\n09i4cSMXXHABXbt25fvf/z5f+MIXGDlyJPPnz+fmm29m5MiR1NbWcvHFF7Ny5Ur27t3L+PHj+elP\nf8ro0aMBuOKKKxgxYgQ/+MEPqKur4/LLL+faa6/ltttuo6SkhFtuuSXupRgaGhq47rrreOKJJ+ja\ntSszZszgBz/4AWbG4sWLueeeezjppJOoqanhG9/4BqNGjTps3s0338wtt9zC/Pnz2bt3L5/+9KeZ\nM2cOvXv3ZsOGDTHziftE5uIbUGfF1PYMrO10JBJ8I6flTWj5cujZM1gvW7dIBC67LLhA35w5cPfd\n0L077N8f3A4cSP5+so/fuxf+8hfYty/olO7WDQYNOvyNf+DA4Ed3bef37RsUnWi1tZDKB4BevWDl\nSnj11aB45MrrPE0Kp4C8/DL06xf/2i9RIhGYOPHgMV25suPHNZVt1NTUsHLlSu69917OPvtsIPjR\nI8CKFStYt24dXcIX8pQpU1i0aBGlpaV85zvf4bLLLuPFF1+Mud2tW7cSiUTYsmULy5Yt4/Of/zyf\n+9zn6NOnz2HrTp8+naFDh7J+/Xp2797N+eefT0VFBV/72tcAWL16NV/60pfYvn07+/fv54EHHjhs\n3sKFC6mpqaGuro6BAwcydepUrr76ampqDl55v20+MfXuHXzjJNs/KnQP3ohadO16MKYjvcnHWac6\n2Viin4vo7b78cnC9oy5dgnWyddu7F956K8jvL3+Bq66C8vLgOJaWBreO3u/ePSiMyTy2pCT4DUX4\n+qWkBJ5+Gk49NdkjACR+Nd129eqVM81WaZfq1Rhz4Qa4jx/v3tBwyAUniXOV3ueecy8pSd/HsdJS\n91WrYu4qrqqqKv/d737XOl1fX+9dunTx+vr6uI/ZuXOnm5k3hHnOmDHDb7rpJnd3r62t9bKyMm9q\nampdf9CgQb569erDtrNt2zbv3r277927t3Xe/fff72effba7uy9atMgrKysPeUyseeecc47PnTu3\ndfq1117z0tJSb2pqSigf9/AYlZa6r1jhvm9fdm91dQdfGKWlwZVNP/zw4G3//kNvBw4cfmtqOvTW\n3Hz4raMaGoLXd2lpzNd5ViimvEeuX423U3XgFGDs2OCsoaVFIJUzkHQ3bQ4fPrz1fnNzMzfccAMP\nP/wwO3bsaL1+1I4dO+gVI+D+/fsf8km/rKyM3bt3H7behg0b2L9/P0OHDgUOfoioqKhoXWdEjG+J\ntJ23ZcsWKisrW6crKys5cOAA27Zti5lPXKNHw4QJQZNDNp1wwqEvjPHjj9zGfQRp6QPJxWaQMKba\n++6jeurUnIopnc9T2vqwClThFJAOvFjS8TpLdRvxrgEVPX/JkiUsXbqU5cuXU1FRwfvvv095eXnL\nWVfSRowYwUc+8hHefffdhOKIN++oo45qbXqDoDCVlpYyePBgNm3aFHc7h0mmgmdCLr5Rt8jFZpBe\nvYJCq+epaBXtL9FbXmepvPZT2caQIUNYv379IfPaFoZIJEL37t0pLy+nsbGR733ve2m5+OCQIUP4\n1Kc+xbXXXkskEsHdWb9+PStWrOjQdi699FJ+9KMfUV9fz+7du7nxxhu55JJLWs+CEi50ufgGlKaY\nCv3Tq/IrbkVbQLLtu9/9Lv/2b/9Gv379mD17NnD4p/Vp06ZRUVHBsGHDGDt2LKeddlqH9tFesamp\nqeHDDz9k9OjR9OvXjy984Qts3bq1Q9v/8pe/zNSpUznzzDMZNWoUZWVlzJkzJ6H9i0j+0w8JJasK\n/RgVehu68stfupiiiIhkjc5AJKt0jESyQ2cgIiKSNSogIhmk8TLyW6HnlyoVEBERSUpG+0DMbAFw\nPrDN3cfFWH4ssBA4EbjB3WeH84cDNcBgoBm4x93ntH181HbUB5KndIxEsiMf+kAWApPbWf4ucA3w\nwzbzDwDXufsY4FTgm2Z2XGZCFBGRZGS0gLj7M8DOdpbvcPcXCApG9Pyt7v5SeH83sBYYlslYRTKh\n0NvQlV9xy/k+EDOrAiYAq7MbiYiIRMvpiymaWU/gYeBb4ZlIXDNmzKCqqgqAvn37MmHChMwHmIJ0\nDWm7ePFi5s+fz8qVK9MUWedr+ZTX8ovfQpqurq7OqXiUX/Hm13K/vr6edMn4DwnNrBJYGqsTPWqd\nWUCkpRM9nFcCPA782t1/fIR95F0neroKyKJFi7j33ns7fCHEeDp7+NpcPkYihSwfOtEBLLwlsl60\ne4E1RyoeSYtEYNWq4G8nbyN6SNvevXtz++23A/D8889z+umnU15ezgknnEBdXV3rYxYtWsSoUaPo\n3bs3o0aN4v7772fdunXMnDmTVatW0atXL/r16xdzfw0NDXz1q1/lqKOOYsSIEdx0002tb9qLFy/m\njDPO4LrrrmPAgAHcfPPNMee5O//+7/9OVVUVQ4YMYcaMGTQ0NADBZdy7dOnCvffeS2VlJeecc04y\nz2ZBKvQ2dOVX5FIdkaq9G7AE2ALsAzYCVwBfB64Mlw8GNgG7gPfCdXoCpwNNwEvAi8CfgE+3s5/2\nRtw6XMvIZSUlyY9cluI2qqqqfPny5a3Tmzdv9v79+/uTTz7p7u5PPfWU9+/f33fs2OGNjY3eu3dv\nf/31193dfevWrb5mzRp3D0YKnDhxYrv7uvDCC33mzJn+wQcf+DvvvOMnn3yyz5s3r/XxJSUlfued\nd3pTU5Pv3bs35rwFCxb4Mccc4/X19d7Y2OgXXXSRT5061d2D0RTNzKdPn+579uw5ZKTDI4l7jArE\n008/ne0QMkr55S/SMCJhRgtIZ906XEByYEzbtkPa3nbbbT5t2rRD1pk8ebLX1NR4Y2Ojl5eX+69+\n9Sv/4IMPDlnnSAUkl4avjaXQC4hIrkpHAcn5b2FlRMuYtqWlwbClDQ0dLxsNDQeHPE3DmLYbNmzg\noYceol+/fvTr14/y8nKeffZZ3n77bcrKynjwwQeZO3cuQ4cO5YILLuC1115LeLstw9e2bPeqq65i\nx44dret06vC1IlIwirOAtAxdumJF8sOppriNtoMtjRgxgmnTpvHee+/x3nvvsXPnTiKRCNdffz0A\n5557LsuWLWPr1q0ce+yxXHnllTG301b08LUt2921axcvv/xy3FhizWtv+Nr2tlPsCr0NXfkVt+Is\nIJD1MW3bDml7+eWXs3TpUpYtW0ZzczN79+6lrq6OLVu2sH37dh577DH27NlDaWkpPXv2bB02dvDg\nwbz11lvs378/7n5yavhaESkYxVtAsqztkLbDhw/n0Ucf5dZbb2XgwIFUVlZy++2309zcTHNzM7Nn\nz2bYsGEMGDCAFStWMHfuXAAmTZrEmDFjGDJkCIMGDYq5Lw1fmz2FOppdC+VX3DSglGSVjpFIduTL\n70BEilaht6Erv+KmAiIiIklRE5ZklY6RSHaoCUtERLJGBUQkgwq9DV35FTcVEBERSYr6QCSrdIxE\nskN9ICIikjUqIHls5syZ3HLLLdkOQ9pR6G3oyq+45fSQtoUsHSMStlzOREQkG3QGkqOampqyHUKr\nWLF0NL5cyqczFfq1lJRfcSvaApLFEW1jDmkbb1jYiy++mKFDh1JeXk51dTVr1qxp3c4VV1zB97//\nfQDq6uoYMWIEs2fPZvDgwQwbNoxFixbFjUHD3IpIqoqygEQiMHEinHlm8DeZIpLKNmpqaqioqODx\nxx+noaGBf/qnf2pdtmLFCtatW8dvfvMbAKZMmcJf//pXtm/fzoknnshll10Wd7tbt24lEomwZcsW\n5s+fzze/+U3ef//9mOtOnz6dbt26sX79el588UV++9vfMn/+/Nblq1ev5uijj2b79u3ceOONMect\nXLiQmpoa6urqWL9+PZFIhKuvvvqQ/bTNp9gUehu68ityqQ5pmAs3OjikbQ6MaHvYkLaJDAu7c+dO\nNzNvCMdfnzFjht90003u7l5bW+tlZWXe1NTUuv6gQYN89erVh20nl4a5jXeMCkUhj6ntrvzyGWkY\n0rYoO9FbRrRdsyYYjTaZQQlbzkBatpHiiLatooeFbW5u5oYbbuDhhx9mx44dmBlmxo4dO+gVI+D+\n/fu3DvAEUFZWxu7duw9bL3qYWzj4IaKioqJ1HQ1zmx6F3oau/IpbURaQltFoX301eONPZUTbZLcR\nbwCm6PlLlixh6dKlLF++nIqKCt5//33Ky8tT/uFd9DC3icQRb157w9xu2rQp7nZEpDAUZR8IZH1E\n28OGtIXDh4WNRCJ0796d8vJyGhsb+d73vpeWN2QNc9t5Cr0NXfkVt6ItINnWdkhbOPzT+rRp06io\nqGDYsGGMHTuW0047rUP7aK/YaJhbEUlVRq+FZWYLgPOBbe4+LsbyY4GFwInADe4+O2rZp4H/IShy\nC9z9tnb247Hy0HWWcp+OkUh25MO1sBYCk9tZ/i5wDfDD6Jlm1gX4SfjYMcClZnZcpoIUEZGOy2gB\ncfdngJ3tLN/h7i8AB9osOgl43d03uPt+4AHgs5mLVCQzCr0NXfkVt1ztAxkGbIqafiucJyIiOaJg\nvsY7Y8YMqqqqAOjbty8TJkzIbkCSsJZPeS3fuS+k6erq6pyKR/kVb34t9+vr60mXjA8oZWaVwNJY\nnehR68wCIi2d6GZ2CvCv7v7pcPq7BL+ajNmRrk70/KVjJJId+dCJDmDhLZH1WvwBONrMKs2sG3AJ\n8FgmghPJpEJvQ1d+xS2jTVhmtgSoBvqb2UZgFtCN4GxinpkNBv4I9AKazexbwGh3321mVwPLOPg1\n3rWZjFVERDpGY6JLVukYiWRHvjRhiYhIAVIByZKRI0eyfPnylLezePFiJk6cmIaIJBMKvQ1d+RU3\nFZA85+5pveaUhq8VkUQVbwHJ4pi2sYa0BXj++ec5/fTTKS8v54QTTqCurq71MYsWLWLUqFH07t2b\nUaNGcf/997Nu3TpmzpzJqlWr6NWrF/369Yu5Pw1fmz2FPp6E8ityqY5IlQs3OjgioTc0uI8fHwxL\nOH58MN1RKW6jqqrKly9f3jq9efNm79+/vz/55JPu7v7UU095//79fceOHd7Y2Oi9e/f2119/3d3d\nt27d6mvWrHH3YKTAiRMntruvCy+80GfOnOkffPCBv/POO37yySf7vHnzWh9fUlLid955pzc1Nfne\nvXtjzluwYIEfc8wxXl9f742NjX7RRRf51KlT3T0YTdHMfPr06b5nz55DRjo8krjHSEQyijSMSJj1\nN/903DpcQHJgTNu2Q9redtttPm3atEPWmTx5stfU1HhjY6OXl5f7r371K//ggw8OWedIBSSXhq+N\npdALSCEPiequ/PJZOgpIcTZhtYxpW1oK48dDQ0PHy0ZDQ/DY0tK0jGm7YcMGHnroIfr160e/fv0o\nLy/n2Wef5e2336asrIwHH3yQuXPnMnToUC644AJee+21hLfbMnxty3avuuoqduzY0bqOhq8VkWQU\nzLWwOiQHxrRt2/E9YsQIpk2bxt133x1z/XPPPZdzzz2Xffv2ceONN3LllVdSV1d3xA50DV+bXYXe\nhq78iltxnoFA1se0bTuk7eWXX87SpUtZtmwZzc3N7N27l7q6OrZs2cL27dt57LHH2LNnD6WlpfTs\n2bN12NjBgwfz1ltvsX///rj70fC1IpIJxVtAsqztkLbDhw/n0Ucf5dZbb2XgwIFUVlZy++2309zc\nTHNzM7Nnz2bYsGEMGDCAFStWMHfuXAAmTZrEmDFjGDJkCIMGDYq5Lw1fmz2F/jsC5VfcdCkTyapC\nP0a1tbUF3Qyi/PJXOi5logIiWaVjJJIduhaWiIhkjQqISAYVehu68ituKiAiIpIU9YFIVukYiWSH\n+kBERCRrCrqAVFZWYma65fBt6NCh2X6ZZFSht6Erv+JW0Jcyqa+vz3YIKSvk76GD/kFF8llB94GI\niEhs6gMREZGsUQHJcYXexKP88pvyK24qICIikpSM9oGY2QLgfGCbu4+Ls84c4DygEZjh7i+F868F\nvgI0A68AV7j7h3G2oT4QEZEOyIc+kIXA5HgLzew8YJS7HwN8HbgrnH8UcA1wYlh4SoBLMhyriIh0\nQEYLiLs/A+xsZ5XPAjXhuquBPmY2OFzWFehhZiVAGbAlk7HmqkJvg1V++U35Fbds94EMAzZFTW8G\nhrn7FuC/gY3hvF3u/lQW4hMRkThy8oeEZtaX4OykEngfeNjMvuTuS+I9ZsaMGVRVVQHQt29fJkyY\n0PoDvJZPEfk4XV1dnVPxKD/lp/zyc7rlfjp/YJ3xHxKaWSWwNFYnupndBTzt7g+G0+uAs4CJwGR3\n/1o4fypwsrtfHWcf6kQXEemAfOhEB7DwFstjwDQAMzuFoKlqG0HT1Slm9hEzM+AcYG0nxJpzoj89\nFCLll9+UX3HLaBOWmS0BqoH+ZrYRmAV0A9zd57n7E2Y2xczeIPga7xUEC39vZg8DLwL7w7/zMhmr\niIh0jK6FJSJShPKlCUtERApQQgXEApeb2ffD6QozOymzoQkUfhus8stvyq+4JXoG8lPgVODScDoC\n3JmRiEREJC8k1AdiZn9y9xPN7EV3PyGc93/uPj7jESZAfSAiIh3TmX0g+82sK+DhjgcSXORQRESK\nVKIFZA7wCDDIzG4BngFuzVhU0qrQ22CVX35TfsUtod+BuPvPzewFgh/0GXChuxflD/tERCSQaB/I\nKOAtd99nZtXAOKDG3XdlOL6EqA9ERKRjOrMP5JdAk5kdDdwNjADiXthQREQKX6IFpNndDwAXAT9x\n938GhmYuLGlR6G2wyi+/Kb/i1pFvYV1KcOHDx8N5pZkJSURE8kGifSCjgauAVe5+v5mNBC5299sy\nHWAi1AciItIx6egD0cUURUSKUKd1opvZ+Wb2opm9Z2YNZhYxs4ZUdiyJKfQ2WOWX35RfcUt0PJD/\nIehAf0Uf9UVEBBLvA3kaOMfdc/LyJWrCEhHpmHQ0YSV6BnI98ISZ1QH7Wma6++xUdi4iIvkr0a/x\n3gLsAT4C9Iq6SYYVehus8stvyq+4JXoGcpS7j81oJCIiklcS7QP5L+Apd1+W+ZA6Tn0gIiId0ym/\nAzEzA5rCyX3AfoIr8rq7905l5+miAiIi0jGd8juQ8J15jbt3cfePuntvd++VK8Wj0BV6G6zyy2/K\nr7gl2on+gpn9XUYjERGRvJJoH8g64GhgA9DIwSascUd43ALgfGBbvHXNbA5wXrjdGe7+Uji/DzAf\nGEswfO6X3X11nG2oCUtEpAM683cgk5Pc/kLgDqAm1kIzOw8Y5e7HmNnJwF3AKeHiHwNPuPsXzKwE\nKEsyBhERyYCEmrDcfUOsWwKPewbY2c4qnyUsLuHZRR8zG2xmvYGJ7r4wXHbA3Yvy2luF3gar/PKb\n8ituifaBZMowYFPU9OZw3khgh5ktNLM/mdk8M/toViIUEZGYMn45dzOrBJbG6gMxs6XAf7j7c+H0\nUwSXTTHgeeBUd/+jmf0P8L67z4qzD58+fTpVVVUA9O3blwkTJlBdXQ0c/BShaU1rWtPFOt1yv76+\nHoDFixfn/nggRyggdwFPu/uD4fQ64Kxw8Sp3/1g4/wzgO+5+QZx9qBNdRKQDOm08kBRZeIvlMYJh\ncjGzU4Bd7r7N3bcBm8zs4+F65wBrMh5pDor+9FCIlF9+U37FLdFvYSXFzJYA1UB/M9sIzAK6EXwF\neJ67P2FmU8zsDYKv8V4R9fB/BH5uZqXA+jbLREQkyzSkrYhIEcqXJiwRESlAKiA5rtDbYJVfflN+\nxU0FREREkqI+EBGRIqQ+EBERyRoVkBxX6G2wyi+/Kb/ipgIiIiJJUR+IiEgRUh+IiIhkjQpIjiv0\nNljll9+UX3FTARERkaSoD0REpAipDyRaJJLtCA6KRGDVKsV0JIopcbkYl2JKTK7GlAYZvZx7Z2oa\nfwJd7/rmJ9/AAAAPOElEQVQplJVlN5A9e2i66hvYhg14VSVd75qbeEx2+IeB2j/9ieoTT0x4/Zga\nG2n6+kysvh6vqqLrvLugR4/EHhtPovtuL6avfZ26N9dz1sdG0fWeu3Mjpq9eib35Jj5yJF0X3JNy\nTLUvvED13/xN6nF95WtpjStlYUx16/8aHL8ciqn1eZo/L/vHr+1rquV/r6XFJBt/9+yh6dpvJ59T\nlIJpwmrC2F31CbxXr+zGEmmgZ/0rdAGaMXZXjcV7JhBTnOOwsvF9Jvboc/h+OnDcrDFCjw2vhjFB\nY8VovEcKz1MaXjPWGKHHprWsAM4EGocfj/fomcIW0xDT7t302Lzu4PM0/Fi8LJWYYOWeCBPLUntN\nWuNuemx+La1xpaolpoPHL3dianmedg8/Lg3Hr4GJZb1Tiqln1Gtq9/Dj8R69glerWfCyNTs4DXjL\n+Http8O/bklMR+2n6+736b/+D3TFU27CKpgzkJcZx8weKynpk90CcqA5wlwmcjxrWMtovtFzJSXl\nKcTUD/4r1Zi6RPhpVEzf7JNiTKT+YX//exHu3DSRU1nDy4zm6n4rKe2X/Zju2Hzwebqmf+oxAfx3\nio9vG9c/DkhPXKnGNGfzweOXSzG1PE/fGpiemP4nxZh+HBXT/xu0km79g5js0DpxyOs33rJ0POaD\n7RFuWT8R+L8UMgu3WShnIKeObeA3z/UiyycgRCIw+bQIXda+SvPxYxSTYirIuBRT/se06s+9Uz4D\nKZgC0tDgWT8wLSIRePVVGDOGlGOqra2luro6p2JKl0gE7ruvlqlTq3MqpnQ+Tzp+nSsXj1+uHrve\nvVP/FlbBNGHlyoGBIJZTTsl2FIfK1ZhGj9axS0QuxqXjl5hcjSkdCuYMpBDyEBHpLPodiIiIZI0K\nSI4r9GvxKL/8pvyKmwqIiIgkJaN9IGa2ADgf2Obu4+KsMwc4D2gEZrj7S1HLugB/BN5y98+0sx/1\ngYiIdEA+9IEsBCbHW2hm5wGj3P0Y4OvAXW1W+RawJnPhiYhIsjJaQNz9GWBnO6t8FqgJ110N9DGz\nwQBmNhyYAszPZIy5rtDbYJVfflN+xS3bfSDDgE1R05vDeQA/Av6ZdFzkSERE0i4nf0hoZn9P0G/y\nkplVA0dsp5sxYwZVVVUA9O3blwkTJrT+grTlU0Q+TldXV+dUPMpP+Sm//JxuuV9fX0+6ZPyHhGZW\nCSyN1YluZncBT7v7g+H0OuAsgr6Py4EDwEeBXsCv3H1anH2oE11EpAPyoRMdgrOHeEE+BkwDMLNT\ngF3uvs3db3D3Cnf/GHAJsDxe8Sh00Z8eCpHyy2/Kr7hltAnLzJYA1UB/M9sIzAK6Ae7u89z9CTOb\nYmZvEHyN94pMxiMiIumja2GJiBShfGnCEhGRAqQCkuMKvQ1W+eU35VfcVEBERCQp6gMRESlC6gMR\nEZGsUQHJcYXeBqv88pvyK24qICIikhT1gYiIFCH1gYiISNaogOS4Qm+DVX75TfkVNxUQERFJivpA\nRESKkPpAREQka1RAclyht8Eqv/ym/IqbCoiIiCRFfSAiIkVIfSAiIpI1KiA5rtDbYJVfflN+xU0F\nREREkqI+EBGRIqQ+EBERyRoVkBxX6G2wyi+/Kb/ipgIiIiJJyWgfiJktAM4Htrn7uDjrzAHOAxqB\nGe7+kpkNB2qAwUAzcI+7z2lnP+oDERHpgHzoA1kITI630MzOA0a5+zHA14G7wkUHgOvcfQxwKvBN\nMzsuw7GKiBSFSCQ92ylJz2Zic/dnzKyynVU+S3CmgbuvNrM+ZjbY3bcCW8P5u81sLTAMWBdvQ5EI\n9OqVxuBTEInAn/8MY8emHlNtbS3V1dU5FVO6RCJQU1PLtGnVORVTOp8nHb/OlYvHL5mYmprgww8T\nv+3bl/i6u3fDAw+klFKrjBaQBAwDNkVNbw7nbWuZYWZVwARgdXsbqqyEKVOgtDT9QXbE/v3wxBOw\naxf07Zt6TG+/DYsXpzem885LLKaOtgp2ZP39++HJJ4OY/uVfYPLk1J6ndLRg7t8Py5bB++9Dnz5w\n7rmpv562bYN77kk9rt/+Nr1xpaolppbj98lP5kZMTz118HmaNCmIqeW1Ee9ve8veeQcGDEhs3Vh/\nDxyA1auDN+2yMhgzJrHi0NwM3btDt26J3xJZv6wM9uyBnTvT85xnu4C0y8x6Ag8D33L33e2tu3Pn\nDDZurKK8HMrK+lJRMYHjjqsGYN26WoBOmX7jDdi1qxZ3aGiopqoK9u9PZfvVKcf3u9/VsmsXuFfT\n0ABdutQyZEhijzeDtWuD6eOPD5a3N53o+ps3QyQS5NfQUEv37vDJTx55++1Njx6d2uNLSqr55S/B\nvZaGBhgzppqjj4Y1aw7dfsemq1N8PPz2t0E87tVEIlBWVsuwYclvLx3TbY9fjx7wqU9lLx6A0tJq\nHnnk4PEbP76aj3/84PIxY4LX56uv1mJ26DTA2LHB9lqmP/GJIL9Dp+GVV4LHf+ITwePbTr/8cjA9\nblw169bB8uXB+8G+fdV85StBfCUlcPrp1XTrBi+8EEyffXYwvWpVLV26BNNw8JtgLWdCyU633H/3\n3Xr69ElTEXH3jN6ASuDlOMvuAr4YNb0OGBzeLwGeJCgeR9qHjx/v3tDgWdfQ4D5+vHtpqSsmxZQW\nuRiXYsrfmNyDOIK3/xTf31PdwBF3AFXAK3GWTQH+N7x/CvB81LIaYHaC+8iZA+MeHJxVq9LzYnn6\n6adT34inN6Z0aWhwv/POp3MupnQ+Tzp+nSsXj18uHjv39BSQjDZhmdkSoBrob2YbgVlAtzDwee7+\nhJlNMbM3CL/GGz7udOAy4BUzexFw4AZ3fzLevnKlEw+CWE45JdtRHCpXYxo9WscuEbkYl45fYnIx\npnTRtbBERIpQPvwORERECpQKSI4r9GvxKL/8pvyKmwqIiIgkRX0gIiJFSH0gIiKSNSogOa7Q22CV\nX35TfsVNBURERJKiPhARkSKkPhAREckaFZAcV+htsMovvym/4qYCIiIiSVEfiIhIEVIfiIiIZI0K\nSI4r9DZY5ZfflF9xUwEREZGkqA9ERKQIqQ9ERESyRgUkxxV6G6zyy2/Kr7ipgIiISFLUByIiUoTU\nByIiIlmjApLjCr0NVvnlN+VX3DJaQMxsgZltM7OX21lnjpm9bmYvmdmEqPmfNrN1ZvYXM/tOJuPM\nZS+99FK2Q8go5ZfflF9xy/QZyEJgcryFZnYeMMrdjwG+DtwVzu8C/CR87BjgUjM7LsOx5qRdu3Zl\nO4SMUn75TfkVt4wWEHd/BtjZziqfBWrCdVcDfcxsMHAS8Lq7b3D3/cAD4boZkehpanvrxVvWdn57\n0/HupypT+SUyr5Dzi5drups9Oiu/bBy7RLen/70jz89GftnuAxkGbIqafiucF29+RuTyQa6vr08o\ntvbkcgHJ5/wSKSD5lF8yb0CdlV+23mBTzS+X31vSIeNf4zWzSmCpu4+LsWwp8B/u/lw4/RRwPTAS\nmOzuV4bzLwdOcvd/jLMPfYdXRKSDUv0ab0m6AknSZmBE1PTwcF43oCLG/JhSfRJERKTjOqMJy8Jb\nLI8B0wDM7BRgl7tvA/4AHG1mlWbWDbgkXFdERHJERs9AzGwJUA30N7ONwCyCswt393nu/oSZTTGz\nN4BG4AqChU1mdjWwjKDILXD3tZmMVUREOqYgLmUiIiKdL9vfwhIRkTylAiIiIkkp6AJiZmVm9gcz\nm5LtWNLNzI4zs7lm9pCZXZXteNLJzD5rZvPM7H4zOzfb8aSbmY00s/lm9lC2Y0m38H9ukZndbWZf\nynY86VbIxw46/r9X0H0gZnYzEAHWuPsT2Y4nE8zMgMXuPi3bsaSbmfUFfujuX8t2LJlgZg+5+8XZ\njiOdwt9s7XT3/zWzB9z9kmzHlAmFeOyiJfq/l/NnIPEuyHikiy2a2SeBNcA7xP8acdYlm1+4zgXA\n40BOFsdUcgv9C3BnZqNMXhryy3lJ5Dicg1eRaOq0QJNU6McwhfwS+99z95y+AWcAE4CXo+Z1Ad4A\nKoFS4CXguHDZVOBHwAJgNvAb4JFs55Hm/GYDQ6PWfzzbeaQ5t6OA/wQmZTuHTB474BfZziEDOV4G\nTAnvL8l2/OnOL2qdnD92yebXkf+9nD8D8dgXZIx7sUV3v8/dr3X3r7j7dcDPgXs6NegOSDK/64CP\nm9mPzewu4H87NegEpZDbPwDnAJ83sys7M+aOSCG/fWY2F5iQ659uO5oj8AjBcbsTWNp5kSano/mZ\nWb98OXaQVH7X0IH/vWxfyiRZsS62eFKsFd29plMiSq8j5ufudUBdZwaVJonkdgdwR2cGlUaJ5Pce\nMLMzg0qzuDm6+x7gy9kIKo3ayy/fjx20n1+H/vdy/gxERERyU74WkM104GKLeaiQ8yvk3KDw84PC\nz1H5JShfCkjbCzIW2sUWCzm/Qs4NCj8/KPwclV+y+WX7WwIJfItgCbAF2AdsBK4I558HvAa8Dnw3\n23Eqv+LKrRjyK4YclV9q+RX0DwlFRCRz8qUJS0REcowKiIiIJEUFREREkqICIiIiSVEBERGRpKiA\niIhIUlRAREQkKSogIjGYWSRN25llZtclsN5CM7soHfsU6SwqICKx6Re2IkegAiLSDjPrYWZPmdkf\nzez/zOwz4fxKM1sbnjm8ZmY/M7NzzOyZcPpvozYzwcyeC+d/NWrbPwm3sQwYFDX/JjNbbWYvh+O9\niOQkFRCR9u0FLnT3vwUmAf8dtWwUwbjRxwLHAZe6+xnAPwM3Rq33CaAaOA34vpkNMbPPAce4+/HA\n9HBZizvc/WR3HweUmdnfZyg3kZSogIi0z4D/MLP/A54CjjKzlrOFN919TXj/VeB34f1XCIYLbfGo\nu3/o7u8Cy4GTgTOB+wHc/e1wfotzzOz5cBzrs4ExGchLJGX5OiKhSGe5DBgAnODuzWb2JvCRcNm+\nqPWao6abOfR/K7o/xcLlMZlZd+BO4ER332Jms6L2J5JTdAYiElvL+Al9gO1h8TibQ88s7PCHxfRZ\nM+tmZv2BswjGY1gBfNHMupjZUIIzDQiKhQPvmllP4POpJiKSKToDEYmt5azh58DSsAnrj8DaGOu0\nvd/Wy0At0B/4gbtvBR4xs0kETV8bgecA3P19M5sfzn8b+H3qqYhkhsYDERGRpKgJS0REkqICIiIi\nSVEBERGRpKiAiIhIUlRAREQkKSogIiKSFBUQERFJyv8H9yEnMfZpONAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9733f52940>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plots import cross_validation_visualization \n",
    "\n",
    "def cross_validation_rr():\n",
    "    seed = 20\n",
    "    #degrees = range(2,11)\n",
    "    degrees = np.array([1,2])\n",
    "    k_fold = 4\n",
    "    lambdas = np.logspace(-4, 2, 10)\n",
    "    # split data in k fold\n",
    "    k_indices = build_k_indices(y, k_fold, seed)\n",
    "    # define lists to store the loss of training data and test data\n",
    "    # ***************************************************\n",
    "    # cross validation:\n",
    "    # ***************************************************    \n",
    "    rmse_best = np.zeros(len(degrees))\n",
    "    rmse_best_lambda = np.zeros(len(degrees))\n",
    "    for j,degree in enumerate(degrees):\n",
    "        print('\\n Testing for a polynomial of degree ', degree)\n",
    "        rmse_tr = np.zeros(len(lambdas))\n",
    "        rmse_te = np.zeros(len(lambdas))\n",
    "        print('lambda=',end=\"\")\n",
    "        for i,lambda_ in enumerate(lambdas):\n",
    "            print(round(lambda_,6),end=\", \")\n",
    "            loss_tr_tot=0\n",
    "            loss_te_tot=0\n",
    "            for k in range(k_fold+1):\n",
    "                loss_tr_tmp,loss_te_tmp =cross_validation(y,tX,k_indices,k,lambda_,degree)\n",
    "                loss_tr_tot += loss_tr_tmp\n",
    "                loss_te_tot += loss_te_tmp\n",
    "            rmse_tr[i] = loss_tr_tot/k_fold\n",
    "            rmse_te[i] = loss_te_tot/k_fold\n",
    "        rmse_best[j] = min(rmse_te)\n",
    "        rmse_best_lambda[j] = lambdas[int(np.argmin(rmse_te))]\n",
    "        cross_validation_visualization(lambdas, rmse_tr, rmse_te)\n",
    "    print('\\nBest error :',rmse_best)\n",
    "    print('Best lambda :',rmse_best_lambda)\n",
    "    return rmse_best,rmse_best_lambda\n",
    "    #plt.figure()\n",
    "    #plt.plot(degrees,rmse_best)\n",
    "\n",
    "rmse,lambda_ = cross_validation_rr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
